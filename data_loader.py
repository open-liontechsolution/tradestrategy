#!/usr/bin/env python3
"""
Script para cargar datos hist√≥ricos de todas las acciones obtenidas din√°micamente
"""

import yfinance as yf
import pandas as pd
import json
import os
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from typing import Dict, List, Optional, Tuple
import warnings
from config import load_dynamic_stocks_data, YFINANCE_CONFIG

warnings.filterwarnings('ignore')

class DataLoader:
    """
    Cargador de datos hist√≥ricos para acciones obtenidas din√°micamente
    """
    
    def __init__(self, data_dir: str = "historical_data"):
        self.data_dir = data_dir
        self.ensure_data_directory()
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Configuraci√≥n
        self.max_workers = YFINANCE_CONFIG.get('max_workers', 10)
        self.retry_attempts = YFINANCE_CONFIG.get('retry_attempts', 3)
        self.timeout = YFINANCE_CONFIG.get('timeout', 10)
        
        # Configuraci√≥n de filtro por a√±os m√≠nimos
        self.min_years = int(os.getenv('MIN_STOCK_YEARS', '5'))  # Por defecto 5 a√±os
        self.min_date = datetime.now() - timedelta(days=self.min_years * 365)
        
        # Estad√≠sticas
        self.stats = {
            'successful': 0,
            'failed': 0,
            'errors': [],
            'start_time': None,
            'end_time': None
        }
    
    def ensure_data_directory(self):
        """Crear directorio de datos hist√≥ricos si no existe"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
    
    def check_stock_min_history(self, symbol: str) -> bool:
        """Verificar si una acci√≥n tiene el hist√≥rico m√≠nimo requerido"""
        try:
            ticker = yf.Ticker(symbol)
            # Obtener solo los √∫ltimos 30 d√≠as para verificaci√≥n r√°pida
            recent_data = ticker.history(period="1mo", timeout=5)
            
            if recent_data.empty:
                return False
            
            # Obtener informaci√≥n b√°sica de la acci√≥n
            info = ticker.info
            
            # Verificar fecha de primer trading (si est√° disponible)
            first_trade_date = info.get('firstTradeDateEpochUtc')
            if first_trade_date:
                first_date = datetime.fromtimestamp(first_trade_date)
                return first_date <= self.min_date
            
            # Si no hay info de primera fecha, intentar obtener datos hist√≥ricos
            # para verificar si tiene suficiente historia
            test_period = f"{self.min_years}y"
            test_data = ticker.history(period=test_period, timeout=5)
            
            if not test_data.empty:
                # Convertir a datetime naive para comparaci√≥n
                oldest_date = test_data.index.min()
                if hasattr(oldest_date, 'tz_localize'):
                    oldest_date = oldest_date.tz_localize(None)
                elif hasattr(oldest_date, 'replace'):
                    oldest_date = oldest_date.replace(tzinfo=None)
                
                oldest_date = oldest_date.to_pydatetime() if hasattr(oldest_date, 'to_pydatetime') else oldest_date
                required_date = datetime.now() - timedelta(days=self.min_years * 365)
                return oldest_date <= required_date
            
            return False
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error verificando hist√≥rico de {symbol}: {e}")
            return False
    
    def download_stock_data(self, symbol: str, period: str = "max", interval: str = "1wk") -> Optional[pd.DataFrame]:
        """
        Descargar datos hist√≥ricos para una acci√≥n espec√≠fica
        Por defecto usa 'max' para obtener todo el hist√≥rico disponible
        """
        for attempt in range(self.retry_attempts):
            try:
                ticker = yf.Ticker(symbol)
                data = ticker.history(period=period, interval=interval, timeout=self.timeout)
                
                if not data.empty:
                    # Agregar informaci√≥n del s√≠mbolo
                    data['Symbol'] = symbol
                    return data
                
            except Exception as e:
                if attempt == self.retry_attempts - 1:  # √öltimo intento
                    error_msg = f"Error descargando {symbol}: {str(e)}"
                    self.stats['errors'].append(error_msg)
                    print(f"  ‚ùå {error_msg}")
                else:
                    time.sleep(1)  # Pausa antes del retry
        
        return None
    
    def download_batch_data(self, symbols: List[str], period: str = "max", interval: str = "1wk", filter_by_years: bool = True) -> Dict[str, pd.DataFrame]:
        """
        Descargar datos de m√∫ltiples acciones en paralelo
        """
        print(f"üìä Descargando datos hist√≥ricos para {len(symbols)} acciones...")
        print(f"üîß Configuraci√≥n: per√≠odo={period}, intervalo={interval}, workers={self.max_workers}")
        
        if filter_by_years:
            print(f"‚öôÔ∏è Filtrando acciones con m√≠nimo {self.min_years} a√±os de historia...")
            
            # Filtrar acciones por a√±os m√≠nimos
            filtered_symbols = []
            print(f"üîç Verificando historial de {len(symbols)} acciones...")
            
            for i, symbol in enumerate(symbols, 1):
                if self.check_stock_min_history(symbol):
                    filtered_symbols.append(symbol)
                    print(f"  ‚úÖ {symbol} - Hist√≥rico v√°lido ({i}/{len(symbols)})")
                else:
                    print(f"  ‚ùå {symbol} - Hist√≥rico insuficiente ({i}/{len(symbols)})")
                
                # Mostrar progreso cada 20 acciones
                if i % 20 == 0:
                    print(f"  üìà Progreso verificaci√≥n: {i}/{len(symbols)} ({len(filtered_symbols)} v√°lidas)")
            
            symbols = filtered_symbols
            print(f"‚úÖ Filtrado completado: {len(symbols)} acciones v√°lidas de {len(symbols)} originales")
            
            if not symbols:
                print("‚ùå No hay acciones que cumplan el criterio de a√±os m√≠nimos")
                return {}
        
        self.stats['start_time'] = datetime.now()
        successful_data = {}
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Enviar todas las tareas
            future_to_symbol = {
                executor.submit(self.download_stock_data, symbol, period, interval): symbol 
                for symbol in symbols
            }
            
            # Procesar resultados
            for i, future in enumerate(as_completed(future_to_symbol), 1):
                symbol = future_to_symbol[future]
                
                try:
                    data = future.result()
                    
                    if data is not None:
                        successful_data[symbol] = data
                        self.stats['successful'] += 1
                        print(f"  ‚úÖ {symbol} ({i}/{len(symbols)})")
                    else:
                        self.stats['failed'] += 1
                        print(f"  ‚ö†Ô∏è {symbol} - Sin datos ({i}/{len(symbols)})")
                        
                except Exception as e:
                    self.stats['failed'] += 1
                    error_msg = f"Error procesando {symbol}: {str(e)}"
                    self.stats['errors'].append(error_msg)
                    print(f"  ‚ùå {symbol} - {error_msg} ({i}/{len(symbols)})")
                
                # Mostrar progreso cada 50 acciones
                if i % 50 == 0:
                    success_rate = (self.stats['successful'] / i) * 100
                    print(f"  üìà Progreso: {i}/{len(symbols)} ({success_rate:.1f}% √©xito)")
        
        self.stats['end_time'] = datetime.now()
        return successful_data
    
    def save_individual_data(self, data_dict: Dict[str, pd.DataFrame]) -> Dict[str, str]:
        """
        Guardar datos individuales de cada acci√≥n
        """
        print(f"\nüíæ Guardando datos individuales...")
        
        individual_dir = os.path.join(self.data_dir, "individual")
        if not os.path.exists(individual_dir):
            os.makedirs(individual_dir)
        
        saved_files = {}
        
        for symbol, data in data_dict.items():
            try:
                # Limpiar s√≠mbolo para nombre de archivo
                clean_symbol = symbol.replace('.', '_').replace('^', '').replace('/', '_')
                filename = f"{clean_symbol}_{self.timestamp}.csv"
                filepath = os.path.join(individual_dir, filename)
                
                data.to_csv(filepath)
                saved_files[symbol] = filepath
                
            except Exception as e:
                print(f"  ‚ùå Error guardando {symbol}: {e}")
        
        print(f"  ‚úÖ Guardados {len(saved_files)} archivos individuales")
        return saved_files
    
    def create_combined_dataset(self, data_dict: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """
        Crear dataset combinado con todas las acciones
        """
        print(f"\nüîó Creando dataset combinado...")
        
        all_data = []
        
        for symbol, data in data_dict.items():
            # Agregar informaci√≥n adicional
            data_copy = data.copy()
            data_copy['Symbol'] = symbol
            data_copy['Date'] = data_copy.index
            
            # Obtener informaci√≥n adicional del stock
            stock_info = self.get_stock_info(symbol)
            if stock_info:
                for key, value in stock_info.items():
                    data_copy[key] = value
            
            all_data.append(data_copy)
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            print(f"  ‚úÖ Dataset combinado creado: {len(combined_df)} registros")
            return combined_df
        
        return pd.DataFrame()
    
    def get_stock_info(self, symbol: str) -> Optional[Dict]:
        """
        Obtener informaci√≥n adicional de una acci√≥n desde los datos din√°micos
        """
        try:
            dynamic_data = load_dynamic_stocks_data()
            
            for stock in dynamic_data:
                if stock['symbol'] == symbol:
                    return {
                        'Market': stock.get('market', 'Unknown'),
                        'Sector': stock.get('sector', 'Unknown'),
                        'Industry': stock.get('industry', 'Unknown'),
                        'Country': stock.get('country', 'Unknown'),
                        'Exchange': stock.get('exchange', 'Unknown'),
                        'Source': stock.get('source', 'Unknown')
                    }
        except Exception:
            pass
        
        return None
    
    def save_combined_data(self, combined_df: pd.DataFrame) -> str:
        """
        Guardar dataset combinado
        """
        if combined_df.empty:
            return ""
        
        filename = f"combined_historical_data_{self.timestamp}.csv"
        filepath = os.path.join(self.data_dir, filename)
        
        combined_df.to_csv(filepath, index=False)
        print(f"  ‚úÖ Dataset combinado guardado: {filepath}")
        
        return filepath
    
    def generate_summary_report(self, data_dict: Dict[str, pd.DataFrame]) -> str:
        """
        Generar reporte resumen
        """
        print(f"\nüìã Generando reporte resumen...")
        
        duration = self.stats['end_time'] - self.stats['start_time'] if self.stats['end_time'] else timedelta(0)
        
        report = f"""
REPORTE DE CARGA DE DATOS HIST√ìRICOS
====================================

Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Duraci√≥n: {duration}

ESTAD√çSTICAS:
- Acciones procesadas: {self.stats['successful'] + self.stats['failed']}
- Descargas exitosas: {self.stats['successful']}
- Descargas fallidas: {self.stats['failed']}
- Tasa de √©xito: {(self.stats['successful'] / (self.stats['successful'] + self.stats['failed']) * 100):.1f}%

AN√ÅLISIS DE DATOS:
"""
        
        if data_dict:
            # Estad√≠sticas por mercado
            market_stats = {}
            sector_stats = {}
            
            for symbol in data_dict.keys():
                stock_info = self.get_stock_info(symbol)
                if stock_info:
                    market = stock_info.get('Market', 'Unknown')
                    sector = stock_info.get('Sector', 'Unknown')
                    
                    market_stats[market] = market_stats.get(market, 0) + 1
                    sector_stats[sector] = sector_stats.get(sector, 0) + 1
            
            report += "\nAcciones exitosas por mercado:\n"
            for market, count in sorted(market_stats.items()):
                report += f"- {market}: {count} acciones\n"
            
            report += "\nAcciones exitosas por sector:\n"
            for sector, count in sorted(sector_stats.items()):
                if count > 5:  # Solo mostrar sectores con m√°s de 5 acciones
                    report += f"- {sector}: {count} acciones\n"
        
        if self.stats['errors']:
            report += f"\nERRORES ({len(self.stats['errors'])}):\n"
            for error in self.stats['errors'][:10]:  # Mostrar solo los primeros 10 errores
                report += f"- {error}\n"
            
            if len(self.stats['errors']) > 10:
                report += f"... y {len(self.stats['errors']) - 10} errores m√°s\n"
        
        report += "\n" + "="*50 + "\n"
        
        # Guardar reporte
        report_file = os.path.join(self.data_dir, f"load_report_{self.timestamp}.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(report)
        print(f"üìÑ Reporte guardado: {report_file}")
        
        return report_file
    
    def load_all_historical_data(self, period: str = "max", interval: str = "1wk", max_stocks: Optional[int] = None, filter_by_years: bool = True) -> Tuple[Dict[str, pd.DataFrame], str]:
        """
        Cargar datos hist√≥ricos de todas las acciones disponibles
        
        Args:
            period: Per√≠odo de datos ('max' para todo el hist√≥rico)
            interval: Intervalo de datos ('1d', '1wk', '1mo')
            max_stocks: L√≠mite m√°ximo de acciones (None para todas)
            filter_by_years: Si filtrar por a√±os m√≠nimos de historia
        """
        print("üöÄ Iniciando carga masiva de datos hist√≥ricos...")
        print("üìä Obteniendo listado de acciones din√°micas...\n")
        
        # Cargar listado de acciones
        dynamic_stocks = load_dynamic_stocks_data()
        if not dynamic_stocks:
            print("‚ùå No se pudieron cargar las acciones din√°micas")
            return {}, ""
        
        symbols = [stock['symbol'] for stock in dynamic_stocks]
        
        if max_stocks:
            symbols = symbols[:max_stocks]
            print(f"üî¢ Limitando a {max_stocks} acciones para prueba")
        
        print(f"üìà Total de acciones a procesar: {len(symbols)}")
        
        # Mostrar configuraci√≥n de filtrado
        if filter_by_years:
            print(f"‚öôÔ∏è Filtro activado: M√≠nimo {self.min_years} a√±os de historia")
            print(f"üìÖ Fecha m√≠nima requerida: {self.min_date.strftime('%Y-%m-%d')}")
        else:
            print("‚ö†Ô∏è Filtro desactivado: Se procesar√°n todas las acciones")
        
        # Descargar datos
        data_dict = self.download_batch_data(symbols, period, interval, filter_by_years)
        
        if not data_dict:
            print("‚ùå No se pudieron descargar datos")
            return {}, ""
        
        # Guardar datos individuales
        self.save_individual_data(data_dict)
        
        # Crear y guardar dataset combinado
        combined_df = self.create_combined_dataset(data_dict)
        combined_file = self.save_combined_data(combined_df)
        
        # Generar reporte
        report_file = self.generate_summary_report(data_dict)
        
        print(f"\nüéâ ¬°Carga completada!")
        print(f"‚úÖ Datos descargados: {len(data_dict)} acciones")
        print(f"üíæ Archivos generados en: {self.data_dir}/")
        
        return data_dict, combined_file


def main():
    """Funci√≥n principal"""
    
    loader = DataLoader()
    
    # Mostrar configuraci√≥n actual
    print("‚öôÔ∏è CONFIGURACI√ìN ACTUAL:")
    print(f"üìÖ A√±os m√≠nimos requeridos: {loader.min_years}")
    print(f"üìä Fecha m√≠nima: {loader.min_date.strftime('%Y-%m-%d')}")
    print(f"üîß Variable de entorno MIN_STOCK_YEARS: {os.getenv('MIN_STOCK_YEARS', 'No definida (usa 5 por defecto)')}")
    print()
    
    # Realizar una carga de prueba con filtrado
    print("üß™ Realizando carga de prueba con hist√≥rico completo y filtrado...")
    data_dict, combined_file = loader.load_all_historical_data(
        period="max",       # Hist√≥rico completo
        interval="1wk",     # Datos semanales
        max_stocks=20,      # L√≠mite para prueba r√°pida
        filter_by_years=True # Activar filtro
    )
    
    if data_dict:
        print(f"\n‚úÖ Prueba exitosa: {len(data_dict)} acciones cargadas")
        print(f"üìÑ Archivo combinado: {combined_file}")
        print("\nüöÄ Para cargar TODAS las acciones, ejecuta:")
        print("loader.load_all_historical_data(period='1y', interval='1wk', max_stocks=None)")
    else:
        print("‚ùå Error en la carga de prueba")


if __name__ == "__main__":
    main()
